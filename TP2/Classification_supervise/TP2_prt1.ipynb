{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d460f6fb-6d59-4dc7-991e-5115d2a88ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
      "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
      "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
      "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
      "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
      "\n",
      "   ca  thal  target  \n",
      "0   2     3       0  \n",
      "1   0     3       0  \n",
      "2   0     3       0  \n",
      "3   1     3       0  \n",
      "4   3     2       0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1025 entries, 0 to 1024\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1025 non-null   int64  \n",
      " 1   sex       1025 non-null   int64  \n",
      " 2   cp        1025 non-null   int64  \n",
      " 3   trestbps  1025 non-null   int64  \n",
      " 4   chol      1025 non-null   int64  \n",
      " 5   fbs       1025 non-null   int64  \n",
      " 6   restecg   1025 non-null   int64  \n",
      " 7   thalach   1025 non-null   int64  \n",
      " 8   exang     1025 non-null   int64  \n",
      " 9   oldpeak   1025 non-null   float64\n",
      " 10  slope     1025 non-null   int64  \n",
      " 11  ca        1025 non-null   int64  \n",
      " 12  thal      1025 non-null   int64  \n",
      " 13  target    1025 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 112.2 KB\n",
      "None\n",
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64\n",
      "apres la suppression du pr ligne\n",
      "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
      "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
      "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
      "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
      "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
      "\n",
      "   ca  thal  target  \n",
      "0   2     3       0  \n",
      "1   0     3       0  \n",
      "2   0     3       0  \n",
      "3   1     3       0  \n",
      "4   3     2       0  \n"
     ]
    }
   ],
   "source": [
    "# fait par : yasmine el mkhantar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"heart.csv\")\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# Afficher des informations générales sur le dataset\n",
    "print(df.info())\n",
    "\n",
    "# Vérifier les valeurs manquantes\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Conversion des variables catégoriques (si nécessaire)\n",
    "print(\"apres la suppression du pr ligne\")\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dde99c80-7c11-4a00-a1ef-c576299cdd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taille du dataset d'entrainement :  (820, 13)\n",
      "taille du dataset du test : (205, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df.drop(columns = ['target'])\n",
    "y = df['target']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"taille du dataset d'entrainement : \", x_train.shape)\n",
    "print(\"taille du dataset du test :\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abf1677c-9358-4326-8b9b-a3114c60eadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision du model : 0.7902439024390244\n",
      "rapport de classification :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.70      0.77       102\n",
      "           1       0.75      0.88      0.81       103\n",
      "\n",
      "    accuracy                           0.79       205\n",
      "   macro avg       0.80      0.79      0.79       205\n",
      "weighted avg       0.80      0.79      0.79       205\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dell\\Desktop\\Items\\MSID\\S2\\DI\\Analyse-et-Classification-de-Donnees-Clients\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 200 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=200).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Régression Logistique\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "logreg = LogisticRegression(max_iter=200)\n",
    "logreg.fit(x_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(x_test)\n",
    "\n",
    "print(\"precision du model :\", accuracy_score(y_test, y_pred))\n",
    "print(\"rapport de classification :\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "761061ce-b492-4793-909f-6122ae4fd08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision du model : 0.8731707317073171\n",
      "rapport de classification :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.80      0.86       102\n",
      "           1       0.83      0.94      0.88       103\n",
      "\n",
      "    accuracy                           0.87       205\n",
      "   macro avg       0.88      0.87      0.87       205\n",
      "weighted avg       0.88      0.87      0.87       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Modèle de base\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,       # 100 arbres\n",
    "    max_depth=5,            # Profondeur maximale des arbres\n",
    "    min_samples_split=5,    # Minimum 5 échantillons pour split\n",
    "    random_state=42         # Pour reproduire les résultats\n",
    ")\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(x_test)\n",
    "\n",
    "print(\"precision du model :\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"rapport de classification :\\n\", classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b229ffa-7d51-4555-9365-47705e91bef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test 1:\n",
      "n_estimators=50, max_depth=None, min_samples_split=2, min_samples_leaf=1, random_state=0, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       102\n",
      "           1       1.00      0.97      0.99       103\n",
      "\n",
      "    accuracy                           0.99       205\n",
      "   macro avg       0.99      0.99      0.99       205\n",
      "weighted avg       0.99      0.99      0.99       205\n",
      "\n",
      "\n",
      " Test 2:\n",
      "n_estimators=50, max_depth=None, min_samples_split=2, min_samples_leaf=1, random_state=0, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       102\n",
      "           1       1.00      0.97      0.99       103\n",
      "\n",
      "    accuracy                           0.99       205\n",
      "   macro avg       0.99      0.99      0.99       205\n",
      "weighted avg       0.99      0.99      0.99       205\n",
      "\n",
      "\n",
      " Test 3:\n",
      "n_estimators=50, max_depth=None, min_samples_split=2, min_samples_leaf=1, random_state=42, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       102\n",
      "           1       1.00      0.97      0.99       103\n",
      "\n",
      "    accuracy                           0.99       205\n",
      "   macro avg       0.99      0.99      0.99       205\n",
      "weighted avg       0.99      0.99      0.99       205\n",
      "\n",
      "\n",
      " Test 4:\n",
      "n_estimators=50, max_depth=None, min_samples_split=2, min_samples_leaf=1, random_state=42, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       102\n",
      "           1       1.00      0.97      0.99       103\n",
      "\n",
      "    accuracy                           0.99       205\n",
      "   macro avg       0.99      0.99      0.99       205\n",
      "weighted avg       0.99      0.99      0.99       205\n",
      "\n",
      "\n",
      " Test 5:\n",
      "n_estimators=50, max_depth=None, min_samples_split=2, min_samples_leaf=2, random_state=0, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       102\n",
      "           1       0.97      0.97      0.97       103\n",
      "\n",
      "    accuracy                           0.97       205\n",
      "   macro avg       0.97      0.97      0.97       205\n",
      "weighted avg       0.97      0.97      0.97       205\n",
      "\n",
      "\n",
      " Test 6:\n",
      "n_estimators=50, max_depth=None, min_samples_split=2, min_samples_leaf=2, random_state=0, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       102\n",
      "           1       1.00      0.97      0.99       103\n",
      "\n",
      "    accuracy                           0.99       205\n",
      "   macro avg       0.99      0.99      0.99       205\n",
      "weighted avg       0.99      0.99      0.99       205\n",
      "\n",
      "\n",
      " Test 7:\n",
      "n_estimators=50, max_depth=None, min_samples_split=2, min_samples_leaf=2, random_state=42, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94       102\n",
      "           1       0.93      0.97      0.95       103\n",
      "\n",
      "    accuracy                           0.95       205\n",
      "   macro avg       0.95      0.95      0.95       205\n",
      "weighted avg       0.95      0.95      0.95       205\n",
      "\n",
      "\n",
      " Test 8:\n",
      "n_estimators=50, max_depth=None, min_samples_split=2, min_samples_leaf=2, random_state=42, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       102\n",
      "           1       0.95      0.97      0.96       103\n",
      "\n",
      "    accuracy                           0.96       205\n",
      "   macro avg       0.96      0.96      0.96       205\n",
      "weighted avg       0.96      0.96      0.96       205\n",
      "\n",
      "\n",
      " Test 9:\n",
      "n_estimators=50, max_depth=None, min_samples_split=2, min_samples_leaf=5, random_state=0, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.84      0.88       102\n",
      "           1       0.86      0.92      0.89       103\n",
      "\n",
      "    accuracy                           0.88       205\n",
      "   macro avg       0.89      0.88      0.88       205\n",
      "weighted avg       0.89      0.88      0.88       205\n",
      "\n",
      "\n",
      " Test 10:\n",
      "n_estimators=50, max_depth=None, min_samples_split=2, min_samples_leaf=5, random_state=0, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.87       102\n",
      "           1       0.86      0.90      0.88       103\n",
      "\n",
      "    accuracy                           0.88       205\n",
      "   macro avg       0.88      0.88      0.88       205\n",
      "weighted avg       0.88      0.88      0.88       205\n",
      "\n",
      "\n",
      " Test 11:\n",
      "n_estimators=50, max_depth=None, min_samples_split=2, min_samples_leaf=5, random_state=42, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90       102\n",
      "           1       0.89      0.93      0.91       103\n",
      "\n",
      "    accuracy                           0.91       205\n",
      "   macro avg       0.91      0.91      0.91       205\n",
      "weighted avg       0.91      0.91      0.91       205\n",
      "\n",
      "\n",
      " Test 12:\n",
      "n_estimators=50, max_depth=None, min_samples_split=2, min_samples_leaf=5, random_state=42, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.89       102\n",
      "           1       0.88      0.92      0.90       103\n",
      "\n",
      "    accuracy                           0.90       205\n",
      "   macro avg       0.90      0.90      0.90       205\n",
      "weighted avg       0.90      0.90      0.90       205\n",
      "\n",
      "\n",
      " Test 13:\n",
      "n_estimators=50, max_depth=None, min_samples_split=5, min_samples_leaf=1, random_state=0, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       102\n",
      "           1       1.00      0.97      0.99       103\n",
      "\n",
      "    accuracy                           0.99       205\n",
      "   macro avg       0.99      0.99      0.99       205\n",
      "weighted avg       0.99      0.99      0.99       205\n",
      "\n",
      "\n",
      " Test 14:\n",
      "n_estimators=50, max_depth=None, min_samples_split=5, min_samples_leaf=1, random_state=0, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       102\n",
      "           1       1.00      1.00      1.00       103\n",
      "\n",
      "    accuracy                           1.00       205\n",
      "   macro avg       1.00      1.00      1.00       205\n",
      "weighted avg       1.00      1.00      1.00       205\n",
      "\n",
      "\n",
      " Test 15:\n",
      "n_estimators=50, max_depth=None, min_samples_split=5, min_samples_leaf=1, random_state=42, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       102\n",
      "           1       1.00      0.97      0.99       103\n",
      "\n",
      "    accuracy                           0.99       205\n",
      "   macro avg       0.99      0.99      0.99       205\n",
      "weighted avg       0.99      0.99      0.99       205\n",
      "\n",
      "\n",
      " Test 16:\n",
      "n_estimators=50, max_depth=None, min_samples_split=5, min_samples_leaf=1, random_state=42, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       102\n",
      "           1       1.00      0.97      0.99       103\n",
      "\n",
      "    accuracy                           0.99       205\n",
      "   macro avg       0.99      0.99      0.99       205\n",
      "weighted avg       0.99      0.99      0.99       205\n",
      "\n",
      "\n",
      " Test 17:\n",
      "n_estimators=50, max_depth=None, min_samples_split=5, min_samples_leaf=2, random_state=0, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       102\n",
      "           1       0.95      0.97      0.96       103\n",
      "\n",
      "    accuracy                           0.96       205\n",
      "   macro avg       0.96      0.96      0.96       205\n",
      "weighted avg       0.96      0.96      0.96       205\n",
      "\n",
      "\n",
      " Test 18:\n",
      "n_estimators=50, max_depth=None, min_samples_split=5, min_samples_leaf=2, random_state=0, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       102\n",
      "           1       0.98      1.00      0.99       103\n",
      "\n",
      "    accuracy                           0.99       205\n",
      "   macro avg       0.99      0.99      0.99       205\n",
      "weighted avg       0.99      0.99      0.99       205\n",
      "\n",
      "\n",
      " Test 19:\n",
      "n_estimators=50, max_depth=None, min_samples_split=5, min_samples_leaf=2, random_state=42, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       102\n",
      "           1       1.00      1.00      1.00       103\n",
      "\n",
      "    accuracy                           1.00       205\n",
      "   macro avg       1.00      1.00      1.00       205\n",
      "weighted avg       1.00      1.00      1.00       205\n",
      "\n",
      "\n",
      " Test 20:\n",
      "n_estimators=50, max_depth=None, min_samples_split=5, min_samples_leaf=2, random_state=42, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       102\n",
      "           1       0.97      0.97      0.97       103\n",
      "\n",
      "    accuracy                           0.97       205\n",
      "   macro avg       0.97      0.97      0.97       205\n",
      "weighted avg       0.97      0.97      0.97       205\n",
      "\n",
      "\n",
      " Test 21:\n",
      "n_estimators=50, max_depth=None, min_samples_split=5, min_samples_leaf=5, random_state=0, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.84      0.88       102\n",
      "           1       0.86      0.92      0.89       103\n",
      "\n",
      "    accuracy                           0.88       205\n",
      "   macro avg       0.89      0.88      0.88       205\n",
      "weighted avg       0.89      0.88      0.88       205\n",
      "\n",
      "\n",
      " Test 22:\n",
      "n_estimators=50, max_depth=None, min_samples_split=5, min_samples_leaf=5, random_state=0, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.87       102\n",
      "           1       0.86      0.90      0.88       103\n",
      "\n",
      "    accuracy                           0.88       205\n",
      "   macro avg       0.88      0.88      0.88       205\n",
      "weighted avg       0.88      0.88      0.88       205\n",
      "\n",
      "\n",
      " Test 23:\n",
      "n_estimators=50, max_depth=None, min_samples_split=5, min_samples_leaf=5, random_state=42, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90       102\n",
      "           1       0.89      0.93      0.91       103\n",
      "\n",
      "    accuracy                           0.91       205\n",
      "   macro avg       0.91      0.91      0.91       205\n",
      "weighted avg       0.91      0.91      0.91       205\n",
      "\n",
      "\n",
      " Test 24:\n",
      "n_estimators=50, max_depth=None, min_samples_split=5, min_samples_leaf=5, random_state=42, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.89       102\n",
      "           1       0.88      0.92      0.90       103\n",
      "\n",
      "    accuracy                           0.90       205\n",
      "   macro avg       0.90      0.90      0.90       205\n",
      "weighted avg       0.90      0.90      0.90       205\n",
      "\n",
      "\n",
      " Test 25:\n",
      "n_estimators=50, max_depth=None, min_samples_split=10, min_samples_leaf=1, random_state=0, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       102\n",
      "           1       0.95      0.97      0.96       103\n",
      "\n",
      "    accuracy                           0.96       205\n",
      "   macro avg       0.96      0.96      0.96       205\n",
      "weighted avg       0.96      0.96      0.96       205\n",
      "\n",
      "\n",
      " Test 26:\n",
      "n_estimators=50, max_depth=None, min_samples_split=10, min_samples_leaf=1, random_state=0, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97       102\n",
      "           1       0.98      0.95      0.97       103\n",
      "\n",
      "    accuracy                           0.97       205\n",
      "   macro avg       0.97      0.97      0.97       205\n",
      "weighted avg       0.97      0.97      0.97       205\n",
      "\n",
      "\n",
      " Test 27:\n",
      "n_estimators=50, max_depth=None, min_samples_split=10, min_samples_leaf=1, random_state=42, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94       102\n",
      "           1       0.93      0.96      0.94       103\n",
      "\n",
      "    accuracy                           0.94       205\n",
      "   macro avg       0.94      0.94      0.94       205\n",
      "weighted avg       0.94      0.94      0.94       205\n",
      "\n",
      "\n",
      " Test 28:\n",
      "n_estimators=50, max_depth=None, min_samples_split=10, min_samples_leaf=1, random_state=42, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93       102\n",
      "           1       0.92      0.94      0.93       103\n",
      "\n",
      "    accuracy                           0.93       205\n",
      "   macro avg       0.93      0.93      0.93       205\n",
      "weighted avg       0.93      0.93      0.93       205\n",
      "\n",
      "\n",
      " Test 29:\n",
      "n_estimators=50, max_depth=None, min_samples_split=10, min_samples_leaf=2, random_state=0, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       102\n",
      "           1       0.93      0.97      0.95       103\n",
      "\n",
      "    accuracy                           0.95       205\n",
      "   macro avg       0.95      0.95      0.95       205\n",
      "weighted avg       0.95      0.95      0.95       205\n",
      "\n",
      "\n",
      " Test 30:\n",
      "n_estimators=50, max_depth=None, min_samples_split=10, min_samples_leaf=2, random_state=0, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93       102\n",
      "           1       0.92      0.94      0.93       103\n",
      "\n",
      "    accuracy                           0.93       205\n",
      "   macro avg       0.93      0.93      0.93       205\n",
      "weighted avg       0.93      0.93      0.93       205\n",
      "\n",
      "\n",
      " Test 31:\n",
      "n_estimators=50, max_depth=None, min_samples_split=10, min_samples_leaf=2, random_state=42, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       102\n",
      "           1       0.94      0.94      0.94       103\n",
      "\n",
      "    accuracy                           0.94       205\n",
      "   macro avg       0.94      0.94      0.94       205\n",
      "weighted avg       0.94      0.94      0.94       205\n",
      "\n",
      "\n",
      " Test 32:\n",
      "n_estimators=50, max_depth=None, min_samples_split=10, min_samples_leaf=2, random_state=42, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94       102\n",
      "           1       0.92      0.95      0.94       103\n",
      "\n",
      "    accuracy                           0.94       205\n",
      "   macro avg       0.94      0.94      0.94       205\n",
      "weighted avg       0.94      0.94      0.94       205\n",
      "\n",
      "\n",
      " Test 33:\n",
      "n_estimators=50, max_depth=None, min_samples_split=10, min_samples_leaf=5, random_state=0, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.84      0.88       102\n",
      "           1       0.86      0.92      0.89       103\n",
      "\n",
      "    accuracy                           0.88       205\n",
      "   macro avg       0.89      0.88      0.88       205\n",
      "weighted avg       0.89      0.88      0.88       205\n",
      "\n",
      "\n",
      " Test 34:\n",
      "n_estimators=50, max_depth=None, min_samples_split=10, min_samples_leaf=5, random_state=0, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.87       102\n",
      "           1       0.86      0.90      0.88       103\n",
      "\n",
      "    accuracy                           0.88       205\n",
      "   macro avg       0.88      0.88      0.88       205\n",
      "weighted avg       0.88      0.88      0.88       205\n",
      "\n",
      "\n",
      " Test 35:\n",
      "n_estimators=50, max_depth=None, min_samples_split=10, min_samples_leaf=5, random_state=42, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90       102\n",
      "           1       0.89      0.93      0.91       103\n",
      "\n",
      "    accuracy                           0.91       205\n",
      "   macro avg       0.91      0.91      0.91       205\n",
      "weighted avg       0.91      0.91      0.91       205\n",
      "\n",
      "\n",
      " Test 36:\n",
      "n_estimators=50, max_depth=None, min_samples_split=10, min_samples_leaf=5, random_state=42, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.89       102\n",
      "           1       0.88      0.92      0.90       103\n",
      "\n",
      "    accuracy                           0.90       205\n",
      "   macro avg       0.90      0.90      0.90       205\n",
      "weighted avg       0.90      0.90      0.90       205\n",
      "\n",
      "\n",
      " Test 37:\n",
      "n_estimators=50, max_depth=5, min_samples_split=2, min_samples_leaf=1, random_state=0, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.75      0.84       102\n",
      "           1       0.80      0.95      0.87       103\n",
      "\n",
      "    accuracy                           0.85       205\n",
      "   macro avg       0.87      0.85      0.85       205\n",
      "weighted avg       0.87      0.85      0.85       205\n",
      "\n",
      "\n",
      " Test 38:\n",
      "n_estimators=50, max_depth=5, min_samples_split=2, min_samples_leaf=1, random_state=0, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.80      0.86       102\n",
      "           1       0.83      0.94      0.88       103\n",
      "\n",
      "    accuracy                           0.87       205\n",
      "   macro avg       0.88      0.87      0.87       205\n",
      "weighted avg       0.88      0.87      0.87       205\n",
      "\n",
      "\n",
      " Test 39:\n",
      "n_estimators=50, max_depth=5, min_samples_split=2, min_samples_leaf=1, random_state=42, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.81      0.88       102\n",
      "           1       0.84      0.97      0.90       103\n",
      "\n",
      "    accuracy                           0.89       205\n",
      "   macro avg       0.90      0.89      0.89       205\n",
      "weighted avg       0.90      0.89      0.89       205\n",
      "\n",
      "\n",
      " Test 40:\n",
      "n_estimators=50, max_depth=5, min_samples_split=2, min_samples_leaf=1, random_state=42, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.80      0.88       102\n",
      "           1       0.83      0.97      0.90       103\n",
      "\n",
      "    accuracy                           0.89       205\n",
      "   macro avg       0.90      0.89      0.89       205\n",
      "weighted avg       0.90      0.89      0.89       205\n",
      "\n",
      "\n",
      " Test 41:\n",
      "n_estimators=50, max_depth=5, min_samples_split=2, min_samples_leaf=2, random_state=0, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.76      0.83       102\n",
      "           1       0.80      0.93      0.86       103\n",
      "\n",
      "    accuracy                           0.85       205\n",
      "   macro avg       0.86      0.85      0.85       205\n",
      "weighted avg       0.86      0.85      0.85       205\n",
      "\n",
      "\n",
      " Test 42:\n",
      "n_estimators=50, max_depth=5, min_samples_split=2, min_samples_leaf=2, random_state=0, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.78      0.84       102\n",
      "           1       0.81      0.92      0.86       103\n",
      "\n",
      "    accuracy                           0.85       205\n",
      "   macro avg       0.86      0.85      0.85       205\n",
      "weighted avg       0.86      0.85      0.85       205\n",
      "\n",
      "\n",
      " Test 43:\n",
      "n_estimators=50, max_depth=5, min_samples_split=2, min_samples_leaf=2, random_state=42, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.81      0.88       102\n",
      "           1       0.84      0.97      0.90       103\n",
      "\n",
      "    accuracy                           0.89       205\n",
      "   macro avg       0.90      0.89      0.89       205\n",
      "weighted avg       0.90      0.89      0.89       205\n",
      "\n",
      "\n",
      " Test 44:\n",
      "n_estimators=50, max_depth=5, min_samples_split=2, min_samples_leaf=2, random_state=42, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.80      0.88       102\n",
      "           1       0.83      0.97      0.90       103\n",
      "\n",
      "    accuracy                           0.89       205\n",
      "   macro avg       0.90      0.89      0.89       205\n",
      "weighted avg       0.90      0.89      0.89       205\n",
      "\n",
      "\n",
      " Test 45:\n",
      "n_estimators=50, max_depth=5, min_samples_split=2, min_samples_leaf=5, random_state=0, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.78      0.84       102\n",
      "           1       0.81      0.92      0.86       103\n",
      "\n",
      "    accuracy                           0.85       205\n",
      "   macro avg       0.86      0.85      0.85       205\n",
      "weighted avg       0.86      0.85      0.85       205\n",
      "\n",
      "\n",
      " Test 46:\n",
      "n_estimators=50, max_depth=5, min_samples_split=2, min_samples_leaf=5, random_state=0, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.81      0.86       102\n",
      "           1       0.83      0.91      0.87       103\n",
      "\n",
      "    accuracy                           0.86       205\n",
      "   macro avg       0.87      0.86      0.86       205\n",
      "weighted avg       0.87      0.86      0.86       205\n",
      "\n",
      "\n",
      " Test 47:\n",
      "n_estimators=50, max_depth=5, min_samples_split=2, min_samples_leaf=5, random_state=42, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.81      0.86       102\n",
      "           1       0.83      0.92      0.88       103\n",
      "\n",
      "    accuracy                           0.87       205\n",
      "   macro avg       0.87      0.87      0.87       205\n",
      "weighted avg       0.87      0.87      0.87       205\n",
      "\n",
      "\n",
      " Test 48:\n",
      "n_estimators=50, max_depth=5, min_samples_split=2, min_samples_leaf=5, random_state=42, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.81      0.87       102\n",
      "           1       0.84      0.94      0.89       103\n",
      "\n",
      "    accuracy                           0.88       205\n",
      "   macro avg       0.88      0.88      0.88       205\n",
      "weighted avg       0.88      0.88      0.88       205\n",
      "\n",
      "\n",
      " Test 49:\n",
      "n_estimators=50, max_depth=5, min_samples_split=5, min_samples_leaf=1, random_state=0, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.77      0.85       102\n",
      "           1       0.81      0.95      0.88       103\n",
      "\n",
      "    accuracy                           0.86       205\n",
      "   macro avg       0.88      0.86      0.86       205\n",
      "weighted avg       0.87      0.86      0.86       205\n",
      "\n",
      "\n",
      " Test 50:\n",
      "n_estimators=50, max_depth=5, min_samples_split=5, min_samples_leaf=1, random_state=0, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.78      0.86       102\n",
      "           1       0.82      0.95      0.88       103\n",
      "\n",
      "    accuracy                           0.87       205\n",
      "   macro avg       0.88      0.87      0.87       205\n",
      "weighted avg       0.88      0.87      0.87       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Liste des paramètres à tester\n",
    "n_estimators_list = [50, 100, 200]\n",
    "max_depth_list = [None, 5, 10]\n",
    "min_samples_split_list = [2, 5, 10]\n",
    "min_samples_leaf_list = [1, 2, 5]\n",
    "random_states = [0, 42]\n",
    "use_class_weight = [None, 'balanced']\n",
    "\n",
    "# Compteur de tests\n",
    "test_num = 1\n",
    "max_tests = 50\n",
    "\n",
    "for n in n_estimators_list:\n",
    "    for depth in max_depth_list:\n",
    "        for split in min_samples_split_list:\n",
    "            for leaf in min_samples_leaf_list:\n",
    "                for state in random_states:\n",
    "                    for weight in use_class_weight:\n",
    "                        if test_num > max_tests:\n",
    "                            break  \n",
    "                        print(f\"\\n Test {test_num}:\")\n",
    "                        print(f\"n_estimators={n}, max_depth={depth}, min_samples_split={split}, min_samples_leaf={leaf}, random_state={state}, class_weight={weight}\")\n",
    "                        \n",
    "                        # Création et entraînement du modèle\n",
    "                        rf = RandomForestClassifier(\n",
    "                            n_estimators=n,\n",
    "                            max_depth=depth,\n",
    "                            min_samples_split=split,\n",
    "                            min_samples_leaf=leaf,\n",
    "                            random_state=state,\n",
    "                            class_weight=weight\n",
    "                        )\n",
    "                        rf.fit(x_train, y_train)\n",
    "                        y_pred = rf.predict(x_test)\n",
    "\n",
    "                        # Affichage du rapport de classification\n",
    "                        print(classification_report(y_test, y_pred))\n",
    "                        test_num += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "297fe5c9-bcde-4688-b6eb-69ac4268394c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Matrice pour la régression logistique\n",
    "cm_lr = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Régression Logistique - Matrice de confusion\")\n",
    "plt.show()\n",
    "\n",
    "# Matrice pour Random Forest\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens')\n",
    "plt.title(\"Random Forest - Matrice de confusion\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
