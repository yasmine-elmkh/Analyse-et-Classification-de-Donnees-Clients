{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d460f6fb-6d59-4dc7-991e-5115d2a88ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
      "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
      "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
      "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
      "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
      "\n",
      "   ca  thal  target  \n",
      "0   2     3       0  \n",
      "1   0     3       0  \n",
      "2   0     3       0  \n",
      "3   1     3       0  \n",
      "4   3     2       0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1025 entries, 0 to 1024\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1025 non-null   int64  \n",
      " 1   sex       1025 non-null   int64  \n",
      " 2   cp        1025 non-null   int64  \n",
      " 3   trestbps  1025 non-null   int64  \n",
      " 4   chol      1025 non-null   int64  \n",
      " 5   fbs       1025 non-null   int64  \n",
      " 6   restecg   1025 non-null   int64  \n",
      " 7   thalach   1025 non-null   int64  \n",
      " 8   exang     1025 non-null   int64  \n",
      " 9   oldpeak   1025 non-null   float64\n",
      " 10  slope     1025 non-null   int64  \n",
      " 11  ca        1025 non-null   int64  \n",
      " 12  thal      1025 non-null   int64  \n",
      " 13  target    1025 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 112.2 KB\n",
      "None\n",
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64\n",
      "apres la suppression du pr ligne\n",
      "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
      "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
      "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
      "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
      "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
      "\n",
      "   ca  thal  target  \n",
      "0   2     3       0  \n",
      "1   0     3       0  \n",
      "2   0     3       0  \n",
      "3   1     3       0  \n",
      "4   3     2       0  \n"
     ]
    }
   ],
   "source": [
    "# fait par : yasmine el mkhantar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"heart.csv\")\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# Afficher des informations générales sur le dataset\n",
    "print(df.info())\n",
    "\n",
    "# Vérifier les valeurs manquantes\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Conversion des variables catégoriques (si nécessaire)\n",
    "print(\"apres la suppression du pr ligne\")\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dde99c80-7c11-4a00-a1ef-c576299cdd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taille du dataset d'entrainement :  (820, 13)\n",
      "taille du dataset du test : (205, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df.drop(columns = ['target'])\n",
    "y = df['target']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"taille du dataset d'entrainement : \", x_train.shape)\n",
    "print(\"taille du dataset du test :\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abf1677c-9358-4326-8b9b-a3114c60eadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision du model : 0.7853658536585366\n",
      "rapport de classification :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.70      0.76       102\n",
      "           1       0.74      0.87      0.80       103\n",
      "\n",
      "    accuracy                           0.79       205\n",
      "   macro avg       0.79      0.78      0.78       205\n",
      "weighted avg       0.79      0.79      0.78       205\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\.anaconda\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Régression Logistique\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "logreg = LogisticRegression(max_iter=200)\n",
    "logreg.fit(x_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(x_test)\n",
    "\n",
    "print(\"precision du model :\", accuracy_score(y_test, y_pred))\n",
    "print(\"rapport de classification :\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "761061ce-b492-4793-909f-6122ae4fd08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision du model : 0.8731707317073171\n",
      "rapport de classification :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.80      0.86       102\n",
      "           1       0.83      0.94      0.88       103\n",
      "\n",
      "    accuracy                           0.87       205\n",
      "   macro avg       0.88      0.87      0.87       205\n",
      "weighted avg       0.88      0.87      0.87       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Modèle de base\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,       # 100 arbres\n",
    "    max_depth=5,            # Profondeur maximale des arbres\n",
    "    min_samples_split=5,    # Minimum 5 échantillons pour split\n",
    "    random_state=42         # Pour reproduire les résultats\n",
    ")\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(x_test)\n",
    "\n",
    "print(\"precision du model :\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"rapport de classification :\\n\", classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b229ffa-7d51-4555-9365-47705e91bef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test 1:\n",
      "n_estimators=50, max_depth=None, min_samples_split=2, min_samples_leaf=1, random_state=0, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       102\n",
      "           1       1.00      0.97      0.99       103\n",
      "\n",
      "    accuracy                           0.99       205\n",
      "   macro avg       0.99      0.99      0.99       205\n",
      "weighted avg       0.99      0.99      0.99       205\n",
      "\n",
      "\n",
      " Test 2:\n",
      "n_estimators=50, max_depth=None, min_samples_split=2, min_samples_leaf=1, random_state=0, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       102\n",
      "           1       1.00      0.97      0.99       103\n",
      "\n",
      "    accuracy                           0.99       205\n",
      "   macro avg       0.99      0.99      0.99       205\n",
      "weighted avg       0.99      0.99      0.99       205\n",
      "\n",
      "\n",
      " Test 3:\n",
      "n_estimators=50, max_depth=None, min_samples_split=2, min_samples_leaf=1, random_state=42, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       102\n",
      "           1       1.00      0.97      0.99       103\n",
      "\n",
      "    accuracy                           0.99       205\n",
      "   macro avg       0.99      0.99      0.99       205\n",
      "weighted avg       0.99      0.99      0.99       205\n",
      "\n",
      "\n",
      " Test 4:\n",
      "n_estimators=50, max_depth=None, min_samples_split=2, min_samples_leaf=1, random_state=42, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       102\n",
      "           1       1.00      0.97      0.99       103\n",
      "\n",
      "    accuracy                           0.99       205\n",
      "   macro avg       0.99      0.99      0.99       205\n",
      "weighted avg       0.99      0.99      0.99       205\n",
      "\n",
      "\n",
      " Test 5:\n",
      "n_estimators=50, max_depth=None, min_samples_split=2, min_samples_leaf=2, random_state=0, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       102\n",
      "           1       0.97      0.97      0.97       103\n",
      "\n",
      "    accuracy                           0.97       205\n",
      "   macro avg       0.97      0.97      0.97       205\n",
      "weighted avg       0.97      0.97      0.97       205\n",
      "\n",
      "\n",
      " Test 6:\n",
      "n_estimators=50, max_depth=None, min_samples_split=2, min_samples_leaf=2, random_state=0, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       102\n",
      "           1       1.00      0.97      0.99       103\n",
      "\n",
      "    accuracy                           0.99       205\n",
      "   macro avg       0.99      0.99      0.99       205\n",
      "weighted avg       0.99      0.99      0.99       205\n",
      "\n",
      "\n",
      " Test 7:\n",
      "n_estimators=50, max_depth=None, min_samples_split=2, min_samples_leaf=2, random_state=42, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94       102\n",
      "           1       0.93      0.97      0.95       103\n",
      "\n",
      "    accuracy                           0.95       205\n",
      "   macro avg       0.95      0.95      0.95       205\n",
      "weighted avg       0.95      0.95      0.95       205\n",
      "\n",
      "\n",
      " Test 8:\n",
      "n_estimators=50, max_depth=None, min_samples_split=2, min_samples_leaf=2, random_state=42, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       102\n",
      "           1       0.95      0.97      0.96       103\n",
      "\n",
      "    accuracy                           0.96       205\n",
      "   macro avg       0.96      0.96      0.96       205\n",
      "weighted avg       0.96      0.96      0.96       205\n",
      "\n",
      "\n",
      " Test 9:\n",
      "n_estimators=50, max_depth=None, min_samples_split=2, min_samples_leaf=5, random_state=0, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.84      0.88       102\n",
      "           1       0.86      0.92      0.89       103\n",
      "\n",
      "    accuracy                           0.88       205\n",
      "   macro avg       0.89      0.88      0.88       205\n",
      "weighted avg       0.89      0.88      0.88       205\n",
      "\n",
      "\n",
      " Test 10:\n",
      "n_estimators=50, max_depth=None, min_samples_split=2, min_samples_leaf=5, random_state=0, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.87       102\n",
      "           1       0.86      0.90      0.88       103\n",
      "\n",
      "    accuracy                           0.88       205\n",
      "   macro avg       0.88      0.88      0.88       205\n",
      "weighted avg       0.88      0.88      0.88       205\n",
      "\n",
      "\n",
      " Test 11:\n",
      "n_estimators=50, max_depth=None, min_samples_split=2, min_samples_leaf=5, random_state=42, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90       102\n",
      "           1       0.89      0.93      0.91       103\n",
      "\n",
      "    accuracy                           0.91       205\n",
      "   macro avg       0.91      0.91      0.91       205\n",
      "weighted avg       0.91      0.91      0.91       205\n",
      "\n",
      "\n",
      " Test 12:\n",
      "n_estimators=50, max_depth=None, min_samples_split=2, min_samples_leaf=5, random_state=42, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.89       102\n",
      "           1       0.88      0.92      0.90       103\n",
      "\n",
      "    accuracy                           0.90       205\n",
      "   macro avg       0.90      0.90      0.90       205\n",
      "weighted avg       0.90      0.90      0.90       205\n",
      "\n",
      "\n",
      " Test 13:\n",
      "n_estimators=50, max_depth=None, min_samples_split=5, min_samples_leaf=1, random_state=0, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       102\n",
      "           1       1.00      0.97      0.99       103\n",
      "\n",
      "    accuracy                           0.99       205\n",
      "   macro avg       0.99      0.99      0.99       205\n",
      "weighted avg       0.99      0.99      0.99       205\n",
      "\n",
      "\n",
      " Test 14:\n",
      "n_estimators=50, max_depth=None, min_samples_split=5, min_samples_leaf=1, random_state=0, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       102\n",
      "           1       1.00      1.00      1.00       103\n",
      "\n",
      "    accuracy                           1.00       205\n",
      "   macro avg       1.00      1.00      1.00       205\n",
      "weighted avg       1.00      1.00      1.00       205\n",
      "\n",
      "\n",
      " Test 15:\n",
      "n_estimators=50, max_depth=None, min_samples_split=5, min_samples_leaf=1, random_state=42, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       102\n",
      "           1       1.00      0.97      0.99       103\n",
      "\n",
      "    accuracy                           0.99       205\n",
      "   macro avg       0.99      0.99      0.99       205\n",
      "weighted avg       0.99      0.99      0.99       205\n",
      "\n",
      "\n",
      " Test 16:\n",
      "n_estimators=50, max_depth=None, min_samples_split=5, min_samples_leaf=1, random_state=42, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       102\n",
      "           1       1.00      0.97      0.99       103\n",
      "\n",
      "    accuracy                           0.99       205\n",
      "   macro avg       0.99      0.99      0.99       205\n",
      "weighted avg       0.99      0.99      0.99       205\n",
      "\n",
      "\n",
      " Test 17:\n",
      "n_estimators=50, max_depth=None, min_samples_split=5, min_samples_leaf=2, random_state=0, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       102\n",
      "           1       0.95      0.97      0.96       103\n",
      "\n",
      "    accuracy                           0.96       205\n",
      "   macro avg       0.96      0.96      0.96       205\n",
      "weighted avg       0.96      0.96      0.96       205\n",
      "\n",
      "\n",
      " Test 18:\n",
      "n_estimators=50, max_depth=None, min_samples_split=5, min_samples_leaf=2, random_state=0, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       102\n",
      "           1       0.98      1.00      0.99       103\n",
      "\n",
      "    accuracy                           0.99       205\n",
      "   macro avg       0.99      0.99      0.99       205\n",
      "weighted avg       0.99      0.99      0.99       205\n",
      "\n",
      "\n",
      " Test 19:\n",
      "n_estimators=50, max_depth=None, min_samples_split=5, min_samples_leaf=2, random_state=42, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       102\n",
      "           1       1.00      1.00      1.00       103\n",
      "\n",
      "    accuracy                           1.00       205\n",
      "   macro avg       1.00      1.00      1.00       205\n",
      "weighted avg       1.00      1.00      1.00       205\n",
      "\n",
      "\n",
      " Test 20:\n",
      "n_estimators=50, max_depth=None, min_samples_split=5, min_samples_leaf=2, random_state=42, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       102\n",
      "           1       0.97      0.97      0.97       103\n",
      "\n",
      "    accuracy                           0.97       205\n",
      "   macro avg       0.97      0.97      0.97       205\n",
      "weighted avg       0.97      0.97      0.97       205\n",
      "\n",
      "\n",
      " Test 21:\n",
      "n_estimators=50, max_depth=None, min_samples_split=5, min_samples_leaf=5, random_state=0, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.84      0.88       102\n",
      "           1       0.86      0.92      0.89       103\n",
      "\n",
      "    accuracy                           0.88       205\n",
      "   macro avg       0.89      0.88      0.88       205\n",
      "weighted avg       0.89      0.88      0.88       205\n",
      "\n",
      "\n",
      " Test 22:\n",
      "n_estimators=50, max_depth=None, min_samples_split=5, min_samples_leaf=5, random_state=0, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.87       102\n",
      "           1       0.86      0.90      0.88       103\n",
      "\n",
      "    accuracy                           0.88       205\n",
      "   macro avg       0.88      0.88      0.88       205\n",
      "weighted avg       0.88      0.88      0.88       205\n",
      "\n",
      "\n",
      " Test 23:\n",
      "n_estimators=50, max_depth=None, min_samples_split=5, min_samples_leaf=5, random_state=42, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90       102\n",
      "           1       0.89      0.93      0.91       103\n",
      "\n",
      "    accuracy                           0.91       205\n",
      "   macro avg       0.91      0.91      0.91       205\n",
      "weighted avg       0.91      0.91      0.91       205\n",
      "\n",
      "\n",
      " Test 24:\n",
      "n_estimators=50, max_depth=None, min_samples_split=5, min_samples_leaf=5, random_state=42, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.89       102\n",
      "           1       0.88      0.92      0.90       103\n",
      "\n",
      "    accuracy                           0.90       205\n",
      "   macro avg       0.90      0.90      0.90       205\n",
      "weighted avg       0.90      0.90      0.90       205\n",
      "\n",
      "\n",
      " Test 25:\n",
      "n_estimators=50, max_depth=None, min_samples_split=10, min_samples_leaf=1, random_state=0, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       102\n",
      "           1       0.95      0.97      0.96       103\n",
      "\n",
      "    accuracy                           0.96       205\n",
      "   macro avg       0.96      0.96      0.96       205\n",
      "weighted avg       0.96      0.96      0.96       205\n",
      "\n",
      "\n",
      " Test 26:\n",
      "n_estimators=50, max_depth=None, min_samples_split=10, min_samples_leaf=1, random_state=0, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97       102\n",
      "           1       0.98      0.95      0.97       103\n",
      "\n",
      "    accuracy                           0.97       205\n",
      "   macro avg       0.97      0.97      0.97       205\n",
      "weighted avg       0.97      0.97      0.97       205\n",
      "\n",
      "\n",
      " Test 27:\n",
      "n_estimators=50, max_depth=None, min_samples_split=10, min_samples_leaf=1, random_state=42, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94       102\n",
      "           1       0.93      0.96      0.94       103\n",
      "\n",
      "    accuracy                           0.94       205\n",
      "   macro avg       0.94      0.94      0.94       205\n",
      "weighted avg       0.94      0.94      0.94       205\n",
      "\n",
      "\n",
      " Test 28:\n",
      "n_estimators=50, max_depth=None, min_samples_split=10, min_samples_leaf=1, random_state=42, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93       102\n",
      "           1       0.92      0.94      0.93       103\n",
      "\n",
      "    accuracy                           0.93       205\n",
      "   macro avg       0.93      0.93      0.93       205\n",
      "weighted avg       0.93      0.93      0.93       205\n",
      "\n",
      "\n",
      " Test 29:\n",
      "n_estimators=50, max_depth=None, min_samples_split=10, min_samples_leaf=2, random_state=0, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       102\n",
      "           1       0.93      0.97      0.95       103\n",
      "\n",
      "    accuracy                           0.95       205\n",
      "   macro avg       0.95      0.95      0.95       205\n",
      "weighted avg       0.95      0.95      0.95       205\n",
      "\n",
      "\n",
      " Test 30:\n",
      "n_estimators=50, max_depth=None, min_samples_split=10, min_samples_leaf=2, random_state=0, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93       102\n",
      "           1       0.92      0.94      0.93       103\n",
      "\n",
      "    accuracy                           0.93       205\n",
      "   macro avg       0.93      0.93      0.93       205\n",
      "weighted avg       0.93      0.93      0.93       205\n",
      "\n",
      "\n",
      " Test 31:\n",
      "n_estimators=50, max_depth=None, min_samples_split=10, min_samples_leaf=2, random_state=42, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       102\n",
      "           1       0.94      0.94      0.94       103\n",
      "\n",
      "    accuracy                           0.94       205\n",
      "   macro avg       0.94      0.94      0.94       205\n",
      "weighted avg       0.94      0.94      0.94       205\n",
      "\n",
      "\n",
      " Test 32:\n",
      "n_estimators=50, max_depth=None, min_samples_split=10, min_samples_leaf=2, random_state=42, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94       102\n",
      "           1       0.92      0.95      0.94       103\n",
      "\n",
      "    accuracy                           0.94       205\n",
      "   macro avg       0.94      0.94      0.94       205\n",
      "weighted avg       0.94      0.94      0.94       205\n",
      "\n",
      "\n",
      " Test 33:\n",
      "n_estimators=50, max_depth=None, min_samples_split=10, min_samples_leaf=5, random_state=0, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.84      0.88       102\n",
      "           1       0.86      0.92      0.89       103\n",
      "\n",
      "    accuracy                           0.88       205\n",
      "   macro avg       0.89      0.88      0.88       205\n",
      "weighted avg       0.89      0.88      0.88       205\n",
      "\n",
      "\n",
      " Test 34:\n",
      "n_estimators=50, max_depth=None, min_samples_split=10, min_samples_leaf=5, random_state=0, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.87       102\n",
      "           1       0.86      0.90      0.88       103\n",
      "\n",
      "    accuracy                           0.88       205\n",
      "   macro avg       0.88      0.88      0.88       205\n",
      "weighted avg       0.88      0.88      0.88       205\n",
      "\n",
      "\n",
      " Test 35:\n",
      "n_estimators=50, max_depth=None, min_samples_split=10, min_samples_leaf=5, random_state=42, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90       102\n",
      "           1       0.89      0.93      0.91       103\n",
      "\n",
      "    accuracy                           0.91       205\n",
      "   macro avg       0.91      0.91      0.91       205\n",
      "weighted avg       0.91      0.91      0.91       205\n",
      "\n",
      "\n",
      " Test 36:\n",
      "n_estimators=50, max_depth=None, min_samples_split=10, min_samples_leaf=5, random_state=42, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.89       102\n",
      "           1       0.88      0.92      0.90       103\n",
      "\n",
      "    accuracy                           0.90       205\n",
      "   macro avg       0.90      0.90      0.90       205\n",
      "weighted avg       0.90      0.90      0.90       205\n",
      "\n",
      "\n",
      " Test 37:\n",
      "n_estimators=50, max_depth=5, min_samples_split=2, min_samples_leaf=1, random_state=0, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.75      0.84       102\n",
      "           1       0.80      0.95      0.87       103\n",
      "\n",
      "    accuracy                           0.85       205\n",
      "   macro avg       0.87      0.85      0.85       205\n",
      "weighted avg       0.87      0.85      0.85       205\n",
      "\n",
      "\n",
      " Test 38:\n",
      "n_estimators=50, max_depth=5, min_samples_split=2, min_samples_leaf=1, random_state=0, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.80      0.86       102\n",
      "           1       0.83      0.94      0.88       103\n",
      "\n",
      "    accuracy                           0.87       205\n",
      "   macro avg       0.88      0.87      0.87       205\n",
      "weighted avg       0.88      0.87      0.87       205\n",
      "\n",
      "\n",
      " Test 39:\n",
      "n_estimators=50, max_depth=5, min_samples_split=2, min_samples_leaf=1, random_state=42, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.81      0.88       102\n",
      "           1       0.84      0.97      0.90       103\n",
      "\n",
      "    accuracy                           0.89       205\n",
      "   macro avg       0.90      0.89      0.89       205\n",
      "weighted avg       0.90      0.89      0.89       205\n",
      "\n",
      "\n",
      " Test 40:\n",
      "n_estimators=50, max_depth=5, min_samples_split=2, min_samples_leaf=1, random_state=42, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.80      0.88       102\n",
      "           1       0.83      0.97      0.90       103\n",
      "\n",
      "    accuracy                           0.89       205\n",
      "   macro avg       0.90      0.89      0.89       205\n",
      "weighted avg       0.90      0.89      0.89       205\n",
      "\n",
      "\n",
      " Test 41:\n",
      "n_estimators=50, max_depth=5, min_samples_split=2, min_samples_leaf=2, random_state=0, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.76      0.83       102\n",
      "           1       0.80      0.93      0.86       103\n",
      "\n",
      "    accuracy                           0.85       205\n",
      "   macro avg       0.86      0.85      0.85       205\n",
      "weighted avg       0.86      0.85      0.85       205\n",
      "\n",
      "\n",
      " Test 42:\n",
      "n_estimators=50, max_depth=5, min_samples_split=2, min_samples_leaf=2, random_state=0, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.78      0.84       102\n",
      "           1       0.81      0.92      0.86       103\n",
      "\n",
      "    accuracy                           0.85       205\n",
      "   macro avg       0.86      0.85      0.85       205\n",
      "weighted avg       0.86      0.85      0.85       205\n",
      "\n",
      "\n",
      " Test 43:\n",
      "n_estimators=50, max_depth=5, min_samples_split=2, min_samples_leaf=2, random_state=42, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.81      0.88       102\n",
      "           1       0.84      0.97      0.90       103\n",
      "\n",
      "    accuracy                           0.89       205\n",
      "   macro avg       0.90      0.89      0.89       205\n",
      "weighted avg       0.90      0.89      0.89       205\n",
      "\n",
      "\n",
      " Test 44:\n",
      "n_estimators=50, max_depth=5, min_samples_split=2, min_samples_leaf=2, random_state=42, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.80      0.88       102\n",
      "           1       0.83      0.97      0.90       103\n",
      "\n",
      "    accuracy                           0.89       205\n",
      "   macro avg       0.90      0.89      0.89       205\n",
      "weighted avg       0.90      0.89      0.89       205\n",
      "\n",
      "\n",
      " Test 45:\n",
      "n_estimators=50, max_depth=5, min_samples_split=2, min_samples_leaf=5, random_state=0, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.78      0.84       102\n",
      "           1       0.81      0.92      0.86       103\n",
      "\n",
      "    accuracy                           0.85       205\n",
      "   macro avg       0.86      0.85      0.85       205\n",
      "weighted avg       0.86      0.85      0.85       205\n",
      "\n",
      "\n",
      " Test 46:\n",
      "n_estimators=50, max_depth=5, min_samples_split=2, min_samples_leaf=5, random_state=0, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.81      0.86       102\n",
      "           1       0.83      0.91      0.87       103\n",
      "\n",
      "    accuracy                           0.86       205\n",
      "   macro avg       0.87      0.86      0.86       205\n",
      "weighted avg       0.87      0.86      0.86       205\n",
      "\n",
      "\n",
      " Test 47:\n",
      "n_estimators=50, max_depth=5, min_samples_split=2, min_samples_leaf=5, random_state=42, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.81      0.86       102\n",
      "           1       0.83      0.92      0.88       103\n",
      "\n",
      "    accuracy                           0.87       205\n",
      "   macro avg       0.87      0.87      0.87       205\n",
      "weighted avg       0.87      0.87      0.87       205\n",
      "\n",
      "\n",
      " Test 48:\n",
      "n_estimators=50, max_depth=5, min_samples_split=2, min_samples_leaf=5, random_state=42, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.81      0.87       102\n",
      "           1       0.84      0.94      0.89       103\n",
      "\n",
      "    accuracy                           0.88       205\n",
      "   macro avg       0.88      0.88      0.88       205\n",
      "weighted avg       0.88      0.88      0.88       205\n",
      "\n",
      "\n",
      " Test 49:\n",
      "n_estimators=50, max_depth=5, min_samples_split=5, min_samples_leaf=1, random_state=0, class_weight=None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.77      0.85       102\n",
      "           1       0.81      0.95      0.88       103\n",
      "\n",
      "    accuracy                           0.86       205\n",
      "   macro avg       0.88      0.86      0.86       205\n",
      "weighted avg       0.87      0.86      0.86       205\n",
      "\n",
      "\n",
      " Test 50:\n",
      "n_estimators=50, max_depth=5, min_samples_split=5, min_samples_leaf=1, random_state=0, class_weight=balanced\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.78      0.86       102\n",
      "           1       0.82      0.95      0.88       103\n",
      "\n",
      "    accuracy                           0.87       205\n",
      "   macro avg       0.88      0.87      0.87       205\n",
      "weighted avg       0.88      0.87      0.87       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Liste des paramètres à tester\n",
    "n_estimators_list = [50, 100, 200]\n",
    "max_depth_list = [None, 5, 10]\n",
    "min_samples_split_list = [2, 5, 10]\n",
    "min_samples_leaf_list = [1, 2, 5]\n",
    "random_states = [0, 42]\n",
    "use_class_weight = [None, 'balanced']\n",
    "\n",
    "# Compteur de tests\n",
    "test_num = 1\n",
    "max_tests = 50\n",
    "\n",
    "for n in n_estimators_list:\n",
    "    for depth in max_depth_list:\n",
    "        for split in min_samples_split_list:\n",
    "            for leaf in min_samples_leaf_list:\n",
    "                for state in random_states:\n",
    "                    for weight in use_class_weight:\n",
    "                        if test_num > max_tests:\n",
    "                            break  \n",
    "                        print(f\"\\n Test {test_num}:\")\n",
    "                        print(f\"n_estimators={n}, max_depth={depth}, min_samples_split={split}, min_samples_leaf={leaf}, random_state={state}, class_weight={weight}\")\n",
    "                        \n",
    "                        # Création et entraînement du modèle\n",
    "                        rf = RandomForestClassifier(\n",
    "                            n_estimators=n,\n",
    "                            max_depth=depth,\n",
    "                            min_samples_split=split,\n",
    "                            min_samples_leaf=leaf,\n",
    "                            random_state=state,\n",
    "                            class_weight=weight\n",
    "                        )\n",
    "                        rf.fit(X_train, y_train)\n",
    "                        y_pred = rf.predict(X_test)\n",
    "\n",
    "                        # Affichage du rapport de classification\n",
    "                        print(classification_report(y_test, y_pred))\n",
    "                        test_num += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "297fe5c9-bcde-4688-b6eb-69ac4268394c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAGxCAYAAABso7+iAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAv9ElEQVR4nO3deXgUVdr38V8Hks5CiKxZQEhwggQBieIgi4aAhMUNkN0FBp0LBHQQFczLDKC+JkNU4BkZYBAEFFmVTQUlg4giOCIIKDo4PqCAGkBBiBACJOf9wzc9dnXANHTSser78arrMqdOV52udHH3fdepissYYwQAABwjJNgDAAAAFYvgDwCAwxD8AQBwGII/AAAOQ/AHAMBhCP4AADgMwR8AAIch+AMA4DAEfwAAHIbg74d58+bJ5XJ5lqpVqyo+Pl79+/fXf/7zn6CNa+LEiXK5XEHbv9U777zjdZx+ufTu3TvYwyvV9OnTNW/evHLZdsnvJyQkRHv37vVZf/LkSVWvXl0ul0uDBw++qH1kZWVp5cqVfr2m5PP81VdfXdQ+A+mrr76Sy+Uqt99BRVq/fr1atWqlqKgouVwuv38vv8ZOxwrBUzXYA/gtmjt3rpo0aaLTp0/r/fff11NPPaUNGzbo3//+t2rUqBHs4VUaWVlZSk9P92qrVatWkEZzYdOnT1ft2rUvOviWRbVq1TR37lw9+eSTXu3Lli3T2bNnFRoaetHbzsrKUu/evdWjR48yv+bmm2/Wli1bFB8ff9H7hTdjjPr27avGjRtr9erVioqK0pVXXhnQfcTHx2vLli264oorArpdOAvB/yI0a9ZMrVq1kiR16NBBRUVFmjBhglauXKk//OEPQR5d5ZGcnKzrr78+4NstKChQeHh4pap2lEW/fv00f/58Pf744woJ+W/Rbc6cOerZs6dWr15dIeMoOX516tRRnTp1KmSfTvHtt9/q6NGj6tmzpzp16lQu+3C73eVyXsFZKPsHQMkXgUOHDnnaTp8+rYcfflgtW7ZUTEyMatasqTZt2mjVqlU+r3e5XBo5cqReeuklpaSkKDIyUldffbVef/11n75vvPGGWrZsKbfbraSkJD3zzDOljun06dPKzMxUUlKSwsLCVK9ePY0YMUI//vijV7/ExETdcsstev3115WamqqIiAilpKR49j1v3jylpKQoKipKv//97/XRRx9d7GHysWnTJnXq1EnR0dGKjIxU27Zt9cYbb3j1KSlNr1u3TkOGDFGdOnUUGRmpwsJCSdKSJUvUpk0bRUVFqVq1aurSpYs+/vhjr23s3btX/fv3V0JCgtxut2JjY9WpUyft2LHDcwx2796tjRs3ei5PJCYmBux9lhgyZIgOHDig3NxcT9sXX3yhTZs2aciQIT79y/oZcrlcOnnypObPn+8Zf4cOHSRd+Pidr+z/5ptvqlOnToqJiVFkZKRSUlKUnZ3t1eejjz7Sbbfdppo1ayo8PFypqalaunRpmY7Dt99+q759+yo6OloxMTHq16+f8vLySu17KfspLCzUE088oZSUFIWHh6tWrVpKT0/X5s2bPX38PU/efPNNXXPNNYqIiFCTJk30wgsvePpMnDhR9evXlySNHTvW63M0ePDgUj9TpV2yW7ZsmVq3bu05/o0aNfL6fJyv7O/P+bRhwwbdf//9ql27tmrVqqVevXrp22+/LdNxhT0Q/ANg3759kqTGjRt72goLC3X06FE98sgjWrlypRYtWqT27durV69eevHFF3228cYbb2jatGl64okn9Oqrr6pmzZrq2bOn1zXi9evX6/bbb1d0dLQWL16sp59+WkuXLtXcuXO9tmWMUY8ePfTMM8/o7rvv1htvvKHRo0dr/vz56tixoydwlti5c6cyMzM1duxYLV++XDExMerVq5cmTJig2bNnKysrSy+//LKOHz+uW265RQUFBWU6LsXFxTp37pzXUmLjxo3q2LGjjh8/rjlz5mjRokWKjo7WrbfeqiVLlvhsa8iQIQoNDdVLL72kV155RaGhocrKytKAAQPUtGlTLV26VC+99JLy8/N1ww036LPPPvO8tnv37tq2bZtycnKUm5urGTNmKDU11fMP/IoVK9SoUSOlpqZqy5Yt2rJli1asWFGm9+iP5ORk3XDDDV4B44UXXlBiYmKpWWJZP0NbtmxRRESEunfv7hn/9OnTvbZV2vErzZw5c9S9e3cVFxdr5syZeu211/Tggw/q4MGDnj4bNmxQu3bt9OOPP2rmzJlatWqVWrZsqX79+v3qdeiCggLddNNNWrdunbKzs7Vs2TLFxcWpX79+Pn0vZT/nzp1Tt27d9OSTT+qWW27RihUrNG/ePLVt21b79++XdHHnycMPP6yHHnpIq1atUosWLXTvvffq3XfflSTdd999Wr58uSTpgQceuKjP0ZYtW9SvXz81atRIixcv1htvvKHx48d7nTul8fd8uu+++xQaGqqFCxcqJydH77zzju666y6/xorfOIMymzt3rpFkPvjgA3P27FmTn59v3nzzTRMXF2duvPFGc/bs2fO+9ty5c+bs2bPm3nvvNampqV7rJJnY2Fhz4sQJT1teXp4JCQkx2dnZnrbWrVubhIQEU1BQ4Gk7ceKEqVmzpvnlr/LNN980kkxOTo7XfpYsWWIkmVmzZnnaGjZsaCIiIszBgwc9bTt27DCSTHx8vDl58qSnfeXKlUaSWb169QWP04YNG4ykUpf//Oc/xhhjrr/+elO3bl2Tn5/vdYyaNWtm6tevb4qLi40x/z3m99xzj9c+9u/fb6pWrWoeeOABr/b8/HwTFxdn+vbta4wx5vvvvzeSzNSpUy845quuusqkpaVdsM/FmjBhgpFkjhw5YubOnWvcbrf54YcfzLlz50x8fLyZOHGiMcaYqKgoM2jQoPNu50KfofO99nzH75fr9u3bZ4z5+dhVr17dtG/f3nP8S9OkSROTmprq83m/5ZZbTHx8vCkqKjrva2fMmGEkmVWrVnm1//GPfzSSzNy5cwOynxdffNFIMs8///x5+/h7noSHh5uvv/7a01ZQUGBq1qxphg4d6mnbt2+fkWSefvppr20OGjTINGzY0GcMJZ+NEs8884yRZH788cfzjrtkH788Vv6eT8OHD/faZk5OjpFkvvvuu/PuF/ZC5n8Rrr/+eoWGhio6Olpdu3ZVjRo1tGrVKlWt6j2FYtmyZWrXrp2qVaumqlWrKjQ0VHPmzNHnn3/us8309HRFR0d7fo6NjVXdunX19ddfS/p5RvjWrVvVq1cvhYeHe/qVfLv/pbfffluSfCav9enTR1FRUVq/fr1Xe8uWLVWvXj3PzykpKZJ+ns8QGRnp014ypl8zadIkbd261Wu5/PLLdfLkSf3rX/9S7969Va1aNU//KlWq6O6779bBgwe1Z88er23dcccdXj+/9dZbOnfunO655x6vykJ4eLjS0tL0zjvvSJJq1qypK664Qk8//bQmT56sjz/+WMXFxWUa//lYKxpFRUVlfm2fPn0UFhaml19+WWvWrFFeXt4FJxn68xm6EOvxK83mzZt14sQJDR8+/LzzKb788kv9+9//1p133ilJXsehe/fu+u6773x+d7+0YcMGRUdH67bbbvNqHzhwYED3s3btWoWHh5d6OaXExZwnDRo08PwcHh6uxo0bl/l8KIvrrrtOktS3b18tXbpU33zzza++5mLOJ+vxb9GihaSyn9v47SP4X4QXX3xRW7du1dtvv62hQ4fq888/14ABA7z6LF++XH379lW9evW0YMECbdmyRVu3btWQIUN0+vRpn22WNgve7XZ7SuzHjh1TcXGx4uLifPpZ23744QdVrVrVZzKXy+VSXFycfvjhB6/2mjVrev0cFhZ2wfbSxl+aRo0aqVWrVl6L2+3WsWPHZIwpdZZ5QkKC5z38krVvyfyK6667TqGhoV7LkiVL9P3333ve8/r169WlSxfl5OTommuuUZ06dfTggw8qPz+/TO/DqqSEXrL4M7ErKipK/fr10wsvvKA5c+bopptuUsOGDUvt6+9n6ELKMqP/yJEjkuS5bl2akuP+yCOP+Bz34cOHS5Ln2Jfmhx9+UGxsrE+79TN8qfs5cuSIEhISvCZWljYWf86TXztHA+HGG2/UypUrPV9s69evr2bNmmnRokXnfc3FnE/W9+J2uyUpoO8FlRuz/S9CSkqKZ5Jfenq6ioqKNHv2bL3yyiue+9gXLFigpKQkLVmyxCuLsl5HLKsaNWrI5XKVOjHK2larVi2dO3dOR44c8fqHzRijvLw8T3YRLDVq1FBISIi+++47n3Ulk45q167t1W7NREvWv/LKK+cNniUaNmyoOXPmSPp5gt3SpUs1ceJEnTlzRjNnzvR7/BMnTtTIkSM9P/+yYlMWQ4YM0ezZs7Vr1y69/PLL5+0XyM9QWe6MKPms/PL6vlXJcc/MzFSvXr1K7XOhW9tq1aqlDz/80Kfd+hm+1P3UqVNHmzZtUnFx8Xm/AFTkeRIeHl7q7620LzC33367br/9dhUWFuqDDz5Qdna2Bg4cqMTERLVp08an/8WcTwCZfwDk5OSoRo0aGj9+vKek7HK5FBYW5vWPbl5eXqmz/cuiZLb98uXLvbK+/Px8vfbaa159SzLRBQsWeLW/+uqrOnnyZLndglRWUVFRat26tZYvX+6VaRQXF2vBggWqX7++1+TJ0nTp0kVVq1bV//7v//pUF0qW0jRu3Fh//vOf1bx5c23fvt3T7k8Gl5iY6LUff+/jbtOmjYYMGaKePXuqZ8+e5+3nz2coEBlo27ZtFRMTo5kzZ8oYU2qfK6+8UsnJydq5c+d5j/uFvgylp6crPz/f57bGhQsXBnQ/3bp10+nTpy84MbAiz5PExEQdPnzY646gM2fO6K233jrva9xut9LS0jRp0iRJ8rmLpUQgzic4D5l/ANSoUUOZmZkaM2aMFi5cqLvuuku33HKLli9fruHDh6t37946cOCAnnzyScXHx1/00wCffPJJde3aVZ07d9bDDz+soqIiTZo0SVFRUTp69KinX+fOndWlSxeNHTtWJ06cULt27bRr1y5NmDBBqampuvvuuwP11i9adna2OnfurPT0dD3yyCMKCwvT9OnT9emnn2rRokW/mqkmJibqiSee0Lhx47R3717P3ItDhw7pww8/VFRUlB5//HHt2rVLI0eOVJ8+fZScnKywsDC9/fbb2rVrlx577DHP9po3b67FixdryZIlatSokcLDw9W8efNye/8llYgL8ecz1Lx5c73zzjt67bXXFB8fr+joaL+/lFSrVk3PPvus7rvvPt1000364x//qNjYWH355ZfauXOnpk2bJkn6xz/+oW7duqlLly4aPHiw6tWrp6NHj+rzzz/X9u3btWzZsvPu45577tGUKVN0zz336KmnnlJycrLWrFlTahC8lP0MGDBAc+fO1bBhw7Rnzx6lp6eruLhY//rXv5SSkqL+/ftX6HnSr18/jR8/Xv3799ejjz6q06dP629/+5vPfJHx48fr4MGD6tSpk+rXr68ff/xR//M//6PQ0FClpaWdd/uXej7BgYI63fA3pmSm7NatW33WFRQUmAYNGpjk5GRz7tw5Y4wxf/3rX01iYqJxu90mJSXFPP/88z6ze435ebb/iBEjfLbZsGFDnxncq1evNi1atDBhYWGmQYMG5q9//Wup2ywoKDBjx441DRs2NKGhoSY+Pt7cf//95tixYz77uPnmm332XdqYzjeT2apktv+yZcsu2O+9994zHTt2NFFRUSYiIsJcf/315rXXXvPqc6FjbszPdyCkp6eb6tWrG7fbbRo2bGh69+5t/vnPfxpjjDl06JAZPHiwadKkiYmKijLVqlUzLVq0MFOmTPH8nowx5quvvjIZGRkmOjraSCp1ZvbF+uVs/wspbcZ+WT9DO3bsMO3atTORkZFGkufOhQsdP+ts/xJr1qwxaWlpJioqykRGRpqmTZuaSZMmefXZuXOn6du3r6lbt64JDQ01cXFxpmPHjmbmzJm/ejwOHjxo7rjjDlOtWjUTHR1t7rjjDrN582afGeyXup+CggIzfvx4k5ycbMLCwkytWrVMx44dzebNm736XMp5kpaW5nWXyIXOkTVr1piWLVuaiIgI06hRIzNt2jSf3+Xrr79uunXrZurVq2fCwsJM3bp1Tffu3c17773nsw/rsbqU86nknN2wYcP5DidsxmXMeep7AADAlrjmDwCAwxD8AQBwGII/AAAOQ/AHAMBhCP4AADgMwR8AAIch+AMA4DCV5gl/1R4L7vPmgcrok3Hnf/Y/4GRJ0eX7yGJX5/P/gSt/mdzz/72MYKk0wR8AgErD5o9EpuwPAIDDkPkDAGBl89SY4A8AgJXNy/4EfwAArOwd++1e2AAAAFZk/gAAWFH2BwDAYWxeF7f52wMAAFZk/gAAWFH2BwDAYewd+yn7AwDgNGT+AABYhdg79Sf4AwBgZe/YT9kfAACnIfMHAMCK2f4AADiMvWM/wR8AAB82n/DHNX8AAByGzB8AACt7J/4EfwAAfNh8wh9lfwAAHIbMHwAAK5tP+CP4AwBgZe/YT9kfAACnIfMHAMDK5hP+CP4AAFjZO/ZT9gcAwGnI/AEAsGK2PwAADmPv2E/wBwDAh80n/HHNHwAAhyHzBwDAyuapMcEfAAAryv4AAMBOyPwBALCyd+JP8AcAwAdlfwAAYCdk/gAAWNk8NSb4AwBgRdkfAADYCZk/AABW9k78Cf4AAPjgr/oBAOAwXPMHAAB2QuYPAICVvRN/gj8AAFYuyv4AAMBOyPwBALCwe+ZP8AcAwMLmsZ+yPwAATkPmDwCARYjNU3+CPwAAFna/5k/ZHwAAhyHzBwDAwu6ZP8EfAAALgj8AAA5j89jPNX8AAJyGzB8AAAvK/gAAOIzdgz9lfwAAHIbMHwAAC5fsnfkT/AEAsKDsDwAAbIXgDwCAhcsVuMUf586d05///GclJSUpIiJCjRo10hNPPKHi4mJPH2OMJk6cqISEBEVERKhDhw7avXu3X/sh+AMAYBHicgVs8cekSZM0c+ZMTZs2TZ9//rlycnL09NNP67nnnvP0ycnJ0eTJkzVt2jRt3bpVcXFx6ty5s/Lz88v+/vwaFQAAKDdbtmzR7bffrptvvlmJiYnq3bu3MjIy9NFHH0n6OeufOnWqxo0bp169eqlZs2aaP3++Tp06pYULF5Z5PwR/AAAsXC5XwJbCwkKdOHHCayksLCx1v+3bt9f69ev1xRdfSJJ27typTZs2qXv37pKkffv2KS8vTxkZGZ7XuN1upaWlafPmzWV+fwR/AAAsAhn8s7OzFRMT47VkZ2eXut+xY8dqwIABatKkiUJDQ5WamqpRo0ZpwIABkqS8vDxJUmxsrNfrYmNjPevKglv9AACwCOSdfpmZmRo9erRXm9vtLrXvkiVLtGDBAi1cuFBXXXWVduzYoVGjRikhIUGDBg36xfi8B2iM8ev2RII/AADlyO12nzfYWz366KN67LHH1L9/f0lS8+bN9fXXXys7O1uDBg1SXFycpJ8rAPHx8Z7XHT582KcacCGU/QEAsAhk2d8fp06dUkiId2iuUqWK51a/pKQkxcXFKTc317P+zJkz2rhxo9q2bVvm/ZD5AwBgEawn/N1666166qmn1KBBA1111VX6+OOPNXnyZA0ZMsQzrlGjRikrK0vJyclKTk5WVlaWIiMjNXDgwDLvh+APAEAl8dxzz+kvf/mLhg8frsOHDyshIUFDhw7V+PHjPX3GjBmjgoICDR8+XMeOHVPr1q21bt06RUdHl3k/LmOMKY834K9qj10X7CEAlc4n414O9hCASikpunG5bj/28RsCtq1DE94L2LYChcwfAAAL/rAPAACwFTJ/AAAsbJ74E/wBALCi7A8AAGyFzB8AAAu7Z/4EfwAALEII/gAAOIvNYz/X/AEAcBoyfwAALLjmDwCAw7hE8IfNVAmponE3/VF9W3ZVbHQt5Z34QS9vf12T3p4jY4yqhlTR+Iz71aVJOyXWrKcTp3/Shi8/1Pi105SX/32whw+Ui8Vzl+n9DZt18KtvFOYOU9MWTTTkgcG6PLG+p48xRgtmLdLaFW/pp/yfdOVVjTVi7DAlXtEwiCMH/Mc1fwcanXaP7m19hx5e9bSundxXf1n7N/3pxrt0f9t+kqTI0HC1rNdEk9bPUfu/3a2BL43R72o30NJBzwZ55ED5+WT7p7q1z82aMvdpZf/9SRUVFWncyPE6XXDa02fZ/Fe1YuFKDR8zVH+bP1k1a9XQ/xkxXqdOngriyFEeXC5XwJbKiMzfgX7foLle/2yj3trzviRp/7Hv1KdlF6XWS5EknSg8qdvmjPR6zSOrn9G7I+erfkysDh4/VOFjBsrbU8897vXz6Amj1L/zXfrP51+q+TXNZIzRikWr1f8PfdW+Y1tJ0sOPP6QBGXdrw5sbdfMd3YIxbJSTyhq0A8XvzP/gwYMaN26c0tPTlZKSoqZNmyo9PV3jxo3TgQMHymOMCLAtX+1Uh99dp9/VbiBJahafrDYNr9a6//9loDTVw6upuLhYx0//VFHDBILq1E8nJUnR1X/+G+l53xzSsR+O6ZrrUz19wsJC1fyaZvp817+DMkbgYvmV+W/atEndunXT5ZdfroyMDGVkZMgYo8OHD2vlypV67rnntHbtWrVr1+6C2yksLFRhYaFXmzlXLFdVrkJUhMkb56t6eDVtH71MRaZYVVwhenzdDC3bua7U/u6qYXqi6wgt3fmW8gtPVvBogYpnjNE/Js/RVS2bKvF3P1/PP/bDMUlSjVqXefWtUesyHfrucEUPEeXM5om/f8H/oYce0n333acpU6acd/2oUaO0devWC24nOztbjz/uXWILbRevsPb1/BkOLlLvFp3VP7Wbhiz+sz4/tFfNExpr0i2j9d2JI1q4/Q2vvlVDqmjegKcU4grRQysnBWnEQMX6e85M7fvyKz07u5TPvCUqGGNsXyJ2Irv/Tv1KtT/99FMNGzbsvOuHDh2qTz/99Fe3k5mZqePHj3stodfH+zMUXIL/2/1PmvzOfL2yK1e7D/2vFn+8Vn9/f5Ee6TDYq1/VkCp66c5sJdZM0G1zRpL1wxGm5/xDH7z7oXJmPqU6sbU97TVq1ZAkHfv+mFf/H48eV42al1XkEIFL5lfwj4+P1+bNm8+7fsuWLYqP//Ug7na7Vb16da+Fkn/FiQh1q9gUe7UVFRd7fdMtCfxX1GqgW2eP0NFTxyt6mECFMsbo75Nm6v0NmzVpxlOKqxfntT6uXqxq1Kqhj/+1w9N29uxZfbL9U6W0aFLBo0V5Y7b/LzzyyCMaNmyYtm3bps6dOys2NlYul0t5eXnKzc3V7NmzNXXq1HIaKgJl7b836dGOf9CBH/P0+eG9ujrhSj3QfqBe/Gi1pJ+fA7DgrklqmdBEvec/pBBXFdWtVkuSdKzguM4WnQvm8IFy8fdJM7ThzXc14dlxioiM0NH/n+FHVYuUO9wtl8ulngNu0+K5y5TQIEH1Lk/Q4rlL5Q53K71rWpBHj0CrrEE7UFzGGOPPC5YsWaIpU6Zo27ZtKioqkiRVqVJF1157rUaPHq2+ffte1ECqPXbdRb0O/qsWFqm/ZAzTrVd1UJ1qNfTdie/1ys63lL1+ts4WnVODGvH6bOzqUl/bbdZQvbd3ewWP2Lk+GfdysIfgGF1b3Vpq++gJf1LGrTdJ+u9DftYsf1M/5f+kJs0aa8SY+z2TAlFxkqIbl+v2r5zSNWDb2vPQmwHbVqD4HfxLnD17Vt9///PT3mrXrq3Q0NBLGgjBH/BF8AdKR/C/NBf9kJ/Q0NAyXd8HAOC3xu5lf57wBwCAhd2DP1PsAQBwGDJ/AAAs7J75E/wBALCweeyn7A8AgNOQ+QMAYEHZHwAAh7F78KfsDwCAw5D5AwBgYffMn+APAICFzWM/wR8AACu7Z/5c8wcAwGHI/AEAsLJ55k/wBwDAgrI/AACwFTJ/AAAsbJ74E/wBALCi7A8AAGyFzB8AAAu7Z/4EfwAALOwe/Cn7AwDgMGT+AABY2DzxJ/gDAGBl97I/wR8AAAu7B3+u+QMA4DBk/gAAWNg98yf4AwBgYffgT9kfAACHIfMHAMDC5ok/wR8AACvK/gAAwFbI/AEAsLB75k/wBwDAwu7Bn7I/AAAOQ+YPAICFzRN/gj8AAFZ2L/sT/AEAsLJ58OeaPwAADkPmDwCABWV/AAAcJsTesZ+yPwAATkPmDwCABWV/AAAcJsTmwZ+yPwAADkPmDwCABWV/AAAcxu5lcYI/AAAWXPMHAAAV5ptvvtFdd92lWrVqKTIyUi1bttS2bds8640xmjhxohISEhQREaEOHTpo9+7dfu2D4A8AgIXL5QrY4o9jx46pXbt2Cg0N1dq1a/XZZ5/p2Wef1WWXXebpk5OTo8mTJ2vatGnaunWr4uLi1LlzZ+Xn55d5P5T9AQCwCFbZf9KkSbr88ss1d+5cT1tiYqLn/40xmjp1qsaNG6devXpJkubPn6/Y2FgtXLhQQ4cOLdN+yPwBAChHhYWFOnHihNdSWFhYat/Vq1erVatW6tOnj+rWravU1FQ9//zznvX79u1TXl6eMjIyPG1ut1tpaWnavHlzmcdE8AcAwCKQZf/s7GzFxMR4LdnZ2aXud+/evZoxY4aSk5P11ltvadiwYXrwwQf14osvSpLy8vIkSbGxsV6vi42N9awrC8r+AABYBDIzzszM1OjRo73a3G53qX2Li4vVqlUrZWVlSZJSU1O1e/duzZgxQ/fcc4+nn3UugTHGr/kFZP4AAJQjt9ut6tWrey3nC/7x8fFq2rSpV1tKSor2798vSYqLi5Mknyz/8OHDPtWACyH4AwBgEeJyBWzxR7t27bRnzx6vti+++EINGzaUJCUlJSkuLk65ubme9WfOnNHGjRvVtm3bMu+Hsj8AABbBerzvQw89pLZt2yorK0t9+/bVhx9+qFmzZmnWrFmecY0aNUpZWVlKTk5WcnKysrKyFBkZqYEDB5Z5PwR/AAAqieuuu04rVqxQZmamnnjiCSUlJWnq1Km68847PX3GjBmjgoICDR8+XMeOHVPr1q21bt06RUdHl3k/LmOMKY834K9qj10X7CEAlc4n414O9hCASikpunG5br/vmmEB29bS7jMDtq1AIfMHAMDC3k/2J/gDAOCDP+wDAABshcwfAAALu2f+BH8AACyCdatfRaHsDwCAw5D5AwBgQdkfAACHsXfop+wPAIDjkPkDAGBB2R8AAIexe/Cn7A8AgMOQ+QMAYGH3+/wJ/gAAWNi97E/wBwDAwt6hn2v+AAA4Dpk/AAAWlP0BAHAYuwd/yv4AADgMmT8AABbc6gcAgMPYvSxu9/cHAAAsyPwBALCg7A8AgMMw2x8AANgKmT8AABZ2z/wJ/gAAWHDNv4J8/9TGYA8BqHQiujYO9hCASsnkHizX7YfY/E/7cM0fAACHqTSZPwAAlQVlfwAAHMbuE/4o+wMA4DBk/gAAWLhsPuGP4A8AgIXdr/lT9gcAwGHI/AEAsLD7hD+CPwAAFi6bF8bt/e4AAIAPMn8AACwo+wMA4DB2n+1P8AcAwMLu9/lzzR8AAIch8wcAwIJr/gAAOIzdr/lT9gcAwGHI/AEAsAixeW5M8AcAwIKyPwAAsBUyfwAALOye+RP8AQCwCOEhPwAAwE7I/AEAsKDsDwCAw/CEPwAAHIY/7AMAAGyFzB8AAIsQl71zY4I/AAAWdp/wZ++vNgAAwAeZPwAAFnaf8EfwBwDAwu63+lH2BwDAYcj8AQCwoOwPAIDDUPYHAAC2QuYPAICFi4f8AADgLFzzBwDAYbjmDwAAbIXMHwAAC7s/25/gDwCARYjNr/lT9gcAoBLKzs6Wy+XSqFGjPG3GGE2cOFEJCQmKiIhQhw4dtHv3br+3TfAHAMDC5XIFbLkYW7du1axZs9SiRQuv9pycHE2ePFnTpk3T1q1bFRcXp86dOys/P9+v7RP8AQCwcLlCArb466efftKdd96p559/XjVq1PC0G2M0depUjRs3Tr169VKzZs00f/58nTp1SgsXLvRrHwR/AADKUWFhoU6cOOG1FBYWnrf/iBEjdPPNN+umm27yat+3b5/y8vKUkZHhaXO73UpLS9PmzZv9GhPBHwAAixC5ArZkZ2crJibGa8nOzi51v4sXL9b27dtLXZ+XlydJio2N9WqPjY31rCsrZvsDAGARyFv9MjMzNXr0aK82t9vt0+/AgQP605/+pHXr1ik8PLzMYzPG+D1egj8AAOXI7XaXGuyttm3bpsOHD+vaa6/1tBUVFendd9/VtGnTtGfPHkk/VwDi4+M9fQ4fPuxTDfg1lP0BALBwBfC/surUqZM++eQT7dixw7O0atVKd955p3bs2KFGjRopLi5Oubm5ntecOXNGGzduVNu2bf16f2T+AABYBOMJf9HR0WrWrJlXW1RUlGrVquVpHzVqlLKyspScnKzk5GRlZWUpMjJSAwcO9GtfBH8AACwq6xP+xowZo4KCAg0fPlzHjh1T69attW7dOkVHR/u1HZcxxpTTGP1yuuhUsIcAVDoRXRsHewhApWRyD5br9hd/OT9g2+r/u0EB21agkPkDAGBxMQ/n+S0h+AMAYOHPRL3fInt/tQEAAD7I/AEAsAjGbP+KRPAHAMCCsj8AALAVMn8AACwo+wMA4DCV9SE/gULZHwAAhyHzBwDAgrI/AAAO47J5YZzgDwCAhd0zf3t/tQEAAD7I/AEAsLD7Q34I/gAAWIRQ9gcAAHZC5g8AgAVlfwAAHIbZ/gAAwFbI/AEAsOAhPwAAOAxlfwAAYCtk/gAAWNj9T/oS/AEAsLB72Z/gDwCAhd3v8+eaPwAADkPmDwCABWV/AAAcxu73+dv73QEAAB9k/gAAWNj9T/oS/AEAsGC2PwAAsBUyfwAALJjtDwCAw1D2hyMcOnRYmWPG6cY2HdT6mjbq27OfPtv9WbCHBVSoahFRmnL/RH214AOdev1LvT91pVo1vtqz3uQeLHV5pM+wII4a8B+ZP3Ti+AkNvnOwWv3+Ov39H9NUs1ZNHdx/QNHR0cEeGlChZo9+Ws0Sr9Tdk/6kb384pLs69dI/cxap6b0d9e0PeYrrm+rVv9vv0zVn9DN69b01QRoxygtlf9jeC3PmKjYuTk9mPe5pq1cvIYgjAipeeFi47rihu24fP0TvffIvSdLjL01Wj3ZddP+td+sv857WoWNHvF5ze5sMbdi5Wfvy9gdjyChHITYvjNv73aFMNr69UVc1a6pHRj2qDu07qm+v/np12fJgDwuoUFWrVFHVKlV1+myhV3tB4Wm1b/Z7n/51L6utm1t30py1iytqiKhALpcrYEtlFPDgf+DAAQ0ZMuSCfQoLC3XixAmvpbCw8IKvQfk5ePAbLV28TA0aNtCMWdPVp19vTcrK0WurXgv20IAK81PBSW3e/ZH+cucoxdeKVUhIiO7s1Eutm6QqvmZdn/6DMvoo/9RJLd+0NgijBS5NwIP/0aNHNX/+/Av2yc7OVkxMjNfy9F+fCfRQUEbFxcVKadpEDz70gFKaNlGffr3Vq3dPLV28LNhDAyrU3ZP+JJfLpW8Xb1Phmr16sMcQLXx7pYqKi3z6DunSTy+/vUKFZ0lc7MgVwP8qI7+v+a9evfqC6/fu3fur28jMzNTo0aO92kxV35MLFaNOndpqdEUjr7ZGVyTpn7nrgzQiIDj2fve1OjzcW5HhEaoeGa28o4e1eNx07cs74NWvfbPfq0mD36nfU/cHaaQob5W1XB8ofgf/Hj16yOVyyRhz3j6/dtDcbrfcbrdX2+miU/4OBQHS8pqW+mrf115tX3+1XwkJ8UEaERBcp04X6NTpAl1WLUZdWqVpzPNZXuvv7dZfH32xU7v2fh6kEQKXxu+yf3x8vF599VUVFxeXumzfvr08xolydNc9d+mTXZ9o9j/maP/X+7Xm9bV6Zdmr6jegX7CHBlSojFZp6tKqgxLjLtdN19ygDc8s1Z4DezX3rSWePtGR1dTnhls0e+2iII4U5Y2yv8W1116r7du3q0ePHqWu/7WqACqfZs2v0uS/Pau/TXlO/5gxS/Xq19OYxx7Vzbd2D/bQgAoVExmt7HsfU/3a8Tqa/6Ne3bRW416YpHNF5zx9+ne4XS6XS4veXhXEkaK8VdagHSgu42ekfu+993Ty5El17dq11PUnT57URx99pLS0NL8GQtkf8BXRtXGwhwBUSib3YLlu/6Mj7wdsW63qtAvYtgLF78z/hhtuuOD6qKgovwM/AACVChP+AABwFruX/XnCHwAADkPmDwCABff5AwDgMHYv+xP8AQCwsHvw55o/AAAOQ+YPAIAF1/wBAHAYyv4AAMBWyPwBALCwe+ZP8AcAwMLu1/wp+wMA4DBk/gAAWFD2BwDAYSj7AwAAWyHzBwDAgrI/AAAOQ/AHAMBhuOYPAABshcwfAAALyv4AADiM3YM/ZX8AAByGzB8AAAu7T/gj+AMA4MPewZ+yPwAADkPwBwDAwuVyBWzxR3Z2tq677jpFR0erbt266tGjh/bs2ePVxxijiRMnKiEhQREREerQoYN2797t134I/gAAWLgC+J8/Nm7cqBEjRuiDDz5Qbm6uzp07p4yMDJ08edLTJycnR5MnT9a0adO0detWxcXFqXPnzsrPzy/7+zPGGL9GVk5OF50K9hCASieia+NgDwGolEzuwXLd/t78Pb/eqYzqhSWqsLDQq83tdsvtdv/qa48cOaK6detq48aNuvHGG2WMUUJCgkaNGqWxY8dKkgoLCxUbG6tJkyZp6NChZRoTmT8AABaBzPyzs7MVExPjtWRnZ5dpHMePH5ck1axZU5K0b98+5eXlKSMjw9PH7XYrLS1NmzdvLvP7Y7Y/AAAWgbzVLzMzU6NHj/ZqK0vWb4zR6NGj1b59ezVr1kySlJeXJ0mKjY316hsbG6uvv/66zGMi+AMAYBHIJ/yVtcRvNXLkSO3atUubNm3yWWf9cmKM8esLC2V/AAAqmQceeECrV6/Whg0bVL9+fU97XFycpP9WAEocPnzYpxpwIQR/AAAsgjXb3xijkSNHavny5Xr77beVlJTktT4pKUlxcXHKzc31tJ05c0YbN25U27Zty7wfyv4AAFgE6/G+I0aM0MKFC7Vq1SpFR0d7MvyYmBhFRETI5XJp1KhRysrKUnJyspKTk5WVlaXIyEgNHDiwzPsh+AMAUEnMmDFDktShQwev9rlz52rw4MGSpDFjxqigoEDDhw/XsWPH1Lp1a61bt07R0dFl3g/3+QOVGPf5A6Ur7/v8D57cF7Bt1Y9K+vVOFYzMHwAAC7v/VT8m/AEA4DBk/gAAWATyPv/KiOAPAIAPewd/yv4AADgMmT8AABb2zvsJ/gAA+LD7bH+CPwAAPuwd/LnmDwCAw5D5AwBgYe+8n+APAEAp7B3+KfsDAOAwZP4AAFjYfbY/mT8AAA5D8AcAwGEo+wMAYMEf9gEAwGHsHvwp+wMA4DAEfwAAHIayPwAAFtzqBwAAbIXgDwCAw1D2BwDAwu6z/Qn+AAD4sHfwp+wPAIDDkPkDAGBh77yf4A8AgA9u9QMAALZC5g8AgA97Z/4EfwAALOwd+in7AwDgOGT+AAD4sHfuT/AHAMCC2f4AAMBWCP4AADgMZX8AACz4wz4AADiOvYM/ZX8AAByGzB8AAAt75/0EfwAAfHCrHwAAsBUyfwAAfNg78yf4AwBgYe/QT9kfAADHIfMHAMCHvXN/gj8AABbM9gcAALZC8AcAwGEo+wMAYGH3P+zjMsaYYA8ClUdhYaGys7OVmZkpt9sd7OEAlQLnBeyG4A8vJ06cUExMjI4fP67q1asHezhApcB5Abvhmj8AAA5D8AcAwGEI/gAAOAzBH17cbrcmTJjApCbgFzgvYDdM+AMAwGHI/AEAcBiCPwAADkPwBwDAYQj+AAA4DMEfAACHIfjDY/r06UpKSlJ4eLiuvfZavffee8EeEhBU7777rm699VYlJCTI5XJp5cqVwR4SEBAEf0iSlixZolGjRmncuHH6+OOPdcMNN6hbt27av39/sIcGBM3Jkyd19dVXa9q0acEeChBQ3OcPSVLr1q11zTXXaMaMGZ62lJQU9ejRQ9nZ2UEcGVA5uFwurVixQj169Aj2UIBLRuYPnTlzRtu2bVNGRoZXe0ZGhjZv3hykUQEAygvBH/r+++9VVFSk2NhYr/bY2Fjl5eUFaVQAgPJC8IeHy+Xy+tkY49MGAPjtI/hDtWvXVpUqVXyy/MOHD/tUAwAAv30EfygsLEzXXnutcnNzvdpzc3PVtm3bII0KAFBeqgZ7AKgcRo8erbvvvlutWrVSmzZtNGvWLO3fv1/Dhg0L9tCAoPnpp5/05Zdfen7et2+fduzYoZo1a6pBgwZBHBlwabjVDx7Tp09XTk6OvvvuOzVr1kxTpkzRjTfeGOxhAUHzzjvvKD093ad90KBBmjdvXsUPCAgQgj8AAA7DNX8AAByG4A8AgMMQ/AEAcBiCPwAADkPwBwDAYQj+AAA4DMEfAACHIfgDAOAwBH8AAByG4A8AgMMQ/AEAcJj/B7zpUcNT7I9EAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Matrice pour la régression logistique\n",
    "cm_lr = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Régression Logistique - Matrice de confusion\")\n",
    "plt.show()\n",
    "\n",
    "# Matrice pour Random Forest\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens')\n",
    "plt.title(\"Random Forest - Matrice de confusion\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e393c620-cd0f-45f3-ac0c-5a4d1c864378",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
